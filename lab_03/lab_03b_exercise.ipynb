{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" style=\"max-width: 1000px\" src=\"https://raw.githubusercontent.com/HSG-AIML-Teaching/EMBA2026-Lab/main/assets/banner.png?raw=1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eGwNwDKEt8lG"
   },
   "source": [
    "<img align=\"right\" style=\"max-width: 200px; height: auto\" src=\"../assets/hsg_logo.png?raw=1\">\n",
    "\n",
    "##  Lab 03 - Supervised Machine Learning: k Nearest-Neighbors - Assignments\n",
    "\n",
    "EMBA: Coding und KÃ¼nstliche Intelligenz, University of St. Gallen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nYpS4wEPt8lI"
   },
   "source": [
    "In the last lab, we saw an application of **supervised machine learning** by using the **k Nearest-Neighbor (k NN) classifier** to classify features derived from delicious real-world **Wine samples**. You learned how to train a model and to evaluate and interpret its results. In this lab, we aim to leverage that knowledge by applying it to a set of related self-coding assignments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Br5f8mEt8lK"
   },
   "source": [
    "As always, please don't hesitate to ask all your questions either during the lab, post them in our CANVAS (StudyNet) forum (https://learning.unisg.ch), or send us an email (using the course email)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D0Jnx-Ljt8lK"
   },
   "source": [
    "## 1. Assignment Objectives:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ybF-i5mQt8lL"
   },
   "source": [
    "Similar today's lab session, after today's self-coding assignments you should be able to:\n",
    "\n",
    "> 1. Know how to setup a **notebook or \"pipeline\"** that solves a simple supervised classification task.\n",
    "> 2. Recognize the **data elements** needed to train and evaluate a supervised machine learning classifier. \n",
    "> 3. Understand how a discriminative **k Nearest-Neighbor (kNN)** classifier can be trained and evaluated.\n",
    "> 4. Know how to use Python's sklearn library to **train** and **evaluate** arbitrary classifiers.\n",
    "> 5. Understand how to **evaluate** and **interpret** the classification results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CZaa0qAnt8lY"
   },
   "source": [
    "## 2. Setup of the Jupyter Notebook Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2yTCqemyt8la"
   },
   "source": [
    "Similarly to the previous labs, we need to import a couple of Python libraries that allow for data analysis and data visualization. In this lab will use the `Pandas`, `Numpy`, `Scikit-Learn`, `Matplotlib` and the `Seaborn` library. Let's import the libraries by the execution of the statements below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "o3ShseCwt8lb",
    "outputId": "1254c7ff-5876-4508-8fde-5528e4d704f3"
   },
   "outputs": [],
   "source": [
    "# import the numpy, scipy and pandas data science library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "# import sklearn data and data pre-processing libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import k-nearest neighbor classifier library\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# import sklearn classification evaluation library\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix \n",
    "\n",
    "# import matplotlib data visualization library\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mFnbcu4yt8le"
   },
   "source": [
    "Enable inline Jupyter notebook plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uLbxWoZit8lf"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PsFqwDkYt8ln"
   },
   "source": [
    "Use the `Seaborn`plotting style in all subsequent visualizations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dMH7Y9-Ht8lo"
   },
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-v0_8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n9HtRmw-t8nJ"
   },
   "source": [
    "## 3. k Nearest-Neighbors (kNN) Classification Assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TfKxtSAMt8qw"
   },
   "source": [
    "### 3.1 Wine Dataset Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OljehqMht8qw"
   },
   "source": [
    "Let's download the delicious **Wine Dataset** that we will use for the following assignments. It is a classic and straightforward multi-class classification dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zTyJoRggt8qx"
   },
   "source": [
    "<img align=\"center\" style=\"max-width: 600px; height: auto\" src=\"https://github.com/GitiHubi/courseAIML/blob/master/lab_03/wine_dataset.jpg?raw=1\">\n",
    "\n",
    "(Source: https://www.empirewine.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lYsN2L2Gt8qx"
   },
   "source": [
    "The data is the result of a chemical analysis of wines grown in the same region in Italy by three different cultivators (types). The dataset consists in total of **178 wines** as well as their corresponding **13 different measurements** taken for different constituents found in the three types of wine. Please, find below the list of the individual measurements (features):\n",
    "\n",
    ">- `Alcohol`\n",
    ">- `Malic acid`\n",
    ">- `Ash`\n",
    ">- `Alcalinity of ash`\n",
    ">- `Magnesium`\n",
    ">- `Total phenols`\n",
    ">- `Flavanoids`\n",
    ">- `Nonflavanoid phenols`\n",
    ">- `Proanthocyanins`\n",
    ">- `Color intensity`\n",
    ">- `Hue`\n",
    ">- `OD280/OD315 of diluted wines`\n",
    ">- `CProline`\n",
    "\n",
    "Further details on the dataset can be obtained from the following puplication: *Forina, M. et al, PARVUS - \"An Extendible Package for Data Exploration, Classification and Correlation.\", Institute of Pharmaceutical and Food Analysis and Technologies, Via Brigata Salerno, 16147 Genoa, Italy.*\n",
    "\n",
    "Let's load the dataset and conduct a preliminary data assessment: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cwm84bmft8qy"
   },
   "outputs": [],
   "source": [
    "wine = datasets.load_wine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ty0vOQ3Lt8q3"
   },
   "source": [
    "Print and inspect feature names of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "colab_type": "code",
    "id": "B9HA0ItTt8q3",
    "outputId": "5e52ea54-57a5-44d8-8ee2-955b6967fa66"
   },
   "outputs": [],
   "source": [
    "wine.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Uxm1svBIt8q6"
   },
   "source": [
    "Print and inspect the class names of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "7cg3VG6mt8q6",
    "outputId": "ccf66fdd-58b9-44ec-a963-d5d01a5256c5"
   },
   "outputs": [],
   "source": [
    "wine.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nl3CY4DVt8q8"
   },
   "source": [
    "Print and inspect the top 10 feature rows of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "colab_type": "code",
    "id": "tI6YnJmvt8q8",
    "outputId": "bd0c259e-e9cb-4e01-87fe-03afd407fd9a"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(wine.data, columns=wine.feature_names).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_XBV6Zoht8q-"
   },
   "source": [
    "Print and inspect the top 10 labels of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "colab_type": "code",
    "id": "coh7WqpKt8q_",
    "outputId": "472ed6f3-127f-4388-b910-c1dd853c1c40"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(wine.target).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HKVBBeXft8rB"
   },
   "source": [
    "Determine and print the feature dimensionality of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "jrjgx9oct8rC",
    "outputId": "cd8a0b89-2c70-4487-c642-d3029e4fb706"
   },
   "outputs": [],
   "source": [
    "wine.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-oLhWbAGt8rE"
   },
   "source": [
    "Determine and print the label dimensionality of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "wxKIAouGt8rF",
    "outputId": "37285902-42fd-42fa-8b87-142b875f8be3"
   },
   "outputs": [],
   "source": [
    "wine.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dV81H6ret8rJ"
   },
   "source": [
    "Plot the data distributions of the distinct features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 990
    },
    "colab_type": "code",
    "id": "I7unVIEWt8rJ",
    "outputId": "f7e68202-43e5-4759-b925-6c27a465b78a"
   },
   "outputs": [],
   "source": [
    "# init the plot\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# prepare the dataset to be plotable using seaborn\n",
    "\n",
    "# convert to Panda's DataFrame\n",
    "wine_plot = pd.DataFrame(wine.data, columns=wine.feature_names)\n",
    "\n",
    "# add class labels to the DataFrame\n",
    "wine_plot['class'] = wine.target\n",
    "\n",
    "# plot a pairplot of the distinct feature distributions\n",
    "sns.pairplot(wine_plot, diag_kind='hist', hue='class');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WbzKED-et8rK"
   },
   "source": [
    "### 3.2 Dataset Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NgRYuUMKt8rL"
   },
   "source": [
    "#### 3.2.1 Feature Re-Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bo6ERPyUt8rL"
   },
   "source": [
    "Let's re-scale the distinct feature values of the **Wine Dataset** using **Min-Max Normalization** using the `MinMaxScaler` class of the `sklearn` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ccNkX14Vt8rM"
   },
   "outputs": [],
   "source": [
    "# init the min-max scaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1), copy=True)\n",
    "\n",
    "# min-max normalize the distinct feature values\n",
    "wine_data_scaled = scaler.fit_transform(wine.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZsWFNsVTt8rS"
   },
   "source": [
    "Print and inspect the top 10 feature rows of the normalized dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "colab_type": "code",
    "id": "1cqcjpJZt8rT",
    "outputId": "be595c68-b074-41ee-f57a-d1846b3f63d9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(wine_data_scaled, columns=wine.feature_names).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tHwTTkWxt8rY"
   },
   "source": [
    "Now that all feature values are scaled to a range between $[0,1]$, let's visualize the derived feature value distributions and inspect their distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 992
    },
    "colab_type": "code",
    "id": "UGDK8Me3t8rZ",
    "outputId": "3af54c21-3275-41d9-f7b2-5484669fd9aa"
   },
   "outputs": [],
   "source": [
    "# init the plot\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# prepare the dataset to be plotable using seaborn\n",
    "\n",
    "# convert to Panda's DataFrame\n",
    "wine_plot = pd.DataFrame(wine_data_scaled, columns=wine.feature_names)\n",
    "\n",
    "# add class labels to the DataFrame\n",
    "wine_plot['class'] = wine.target\n",
    "\n",
    "# plot a pairplot of the distinct feature distributions\n",
    "sns.pairplot(wine_plot, diag_kind='hist', hue='class');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k7PF3yj1t8ra"
   },
   "source": [
    "Excellent, the characteristics of the distinct feature value distributions remained unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jYsmr5Cwt8rb"
   },
   "source": [
    "#### 3.2.2 Extraction of Training- and Evaluation-Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "COf_ZHbrt8rb"
   },
   "source": [
    "We set the fraction of testing records to **30%** of the original dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w_Grln45t8rc"
   },
   "outputs": [],
   "source": [
    "eval_fraction = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore, let's set a random seed to insure reproducibility of the train-test split in potential future runs of the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZizWtHIct8re"
   },
   "source": [
    "Randomly split the **Wine Dataset** into training set and evaluation set using sklearn's `train_test_split` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gj0XNs8Nt8rf"
   },
   "outputs": [],
   "source": [
    "# 70% training and 30% evaluation\n",
    "X_train_scaled, X_eval_scaled, y_train_scaled, y_eval_scaled = train_test_split(wine_data_scaled, wine.target, test_size=eval_fraction, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9FKsJVtxt8rh"
   },
   "source": [
    "Evaluate the training set dimensionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "-YLKYgVst8ri",
    "outputId": "a9578a7f-2b81-4cf2-b98b-1b16d1f49e14"
   },
   "outputs": [],
   "source": [
    "X_train_scaled.shape, y_train_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MMLky8CTt8rj"
   },
   "source": [
    "Evaluate the evaluation set dimensionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "nLB4I8_Gt8rj",
    "outputId": "5345efe3-e423-423c-f272-3e5d58d9de2a"
   },
   "outputs": [],
   "source": [
    "X_eval_scaled.shape, y_eval_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 k Nearest-Neighbor (kNN) Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" style=\"max-width: 700px; height: auto\" src=\"../lab_03/hsg_knn.png\">\n",
    "\n",
    "(Courtesy: Intro to AI & ML lecture, Prof. Dr. Borth, University of St. Gallen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yZ-KsINqt8qh"
   },
   "source": [
    "We recommend you to try the following exercises as part of the self-coding session:\n",
    "\n",
    "**Exercise 1: Train and evaluate the prediction accuracy of the k=1,...,40 Nearest Neighbor models.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Write a Python loop that trains and evaluates the prediction accuracy of all k-Nearest Neighbor parameterizations ranging from k=1,...,40 using the **Manhattan** instead of the **Euclidean** distance. Collect and print the prediction accuracy of each model respectively and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UL_44Y-qt8qi"
   },
   "outputs": [],
   "source": [
    "# ***************************************************\n",
    "# INSERT YOUR SOLUTION/CODE HERE\n",
    "# ***************************************************\n",
    "\n",
    "# ***************************************************\n",
    "# Task 1: define range k=1 through k=40 to be evaluated\n",
    "# ***************************************************\n",
    "k_range = ???\n",
    "\n",
    "# ***************************************************\n",
    "# Task 2: init evaluation accuracy score array\n",
    "# ***************************************************\n",
    "eval_accuracy_scores_scaled = ???\n",
    "\n",
    "# ***************************************************\n",
    "# we use a for-loop to iterate over the distinct k values\n",
    "# ***************************************************\n",
    "for k in k_range:\n",
    "    \n",
    "    # ***************************************************\n",
    "    # Task 3: init the k-NN classifier of the current k-value\n",
    "    # ***************************************************\n",
    "    knn = ???\n",
    "    \n",
    "    # ***************************************************\n",
    "    # Task 4: train the k-NN classifer on the training data\n",
    "    # ***************************************************\n",
    "    knn.fit(???)\n",
    "    \n",
    "    # ***************************************************\n",
    "    # Task 5: evaluate the k-NN classifier on the evaluation data\n",
    "    # ***************************************************\n",
    "    y_eval_pred_scaled = knn.predict(???)\n",
    "    \n",
    "    # ***************************************************\n",
    "    # Task 6: collect the classification accuracy of the current k on the evaluation data\n",
    "    # ***************************************************\n",
    "    eval_accuracy_scores_scaled.append(metrics.accuracy_score(???))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2: Visualize the model prediction accuracy for the distinct values of k=1,...,40.**\n",
    "\n",
    "> Plot the prediction accuracy collected for each model above. The plot should display the **distinct values of k at the x-axis** and the corresponding **model prediction accuracy on the y-axis**. What kind of behaviour in terms of prediction accuracy can be observed with increasing k?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***************************************************\n",
    "# INSERT YOUR SOLUTION/CODE HERE\n",
    "# ***************************************************\n",
    "\n",
    "# ***************************************************\n",
    "# prepare plot\n",
    "# ***************************************************\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# ***************************************************\n",
    "# Task 1: plot the classification accuracy of distinct k's\n",
    "# ***************************************************\n",
    "ax.plot(???, eval_accuracy_scores_scaled, color='green', marker='o')\n",
    "\n",
    "# ***************************************************\n",
    "# Note: the following code lines will plot the confusion matrix (no need to change them)\n",
    "# ***************************************************\n",
    "\n",
    "# add grid\n",
    "ax.grid(linestyle='dotted')\n",
    "\n",
    "# add axis range and legends\n",
    "ax.set_xlabel(\"[$k$-Nearest-Neighbors]\", fontsize=10)\n",
    "ax.set_ylabel(\"[% classification accuracy]\", fontsize=10)\n",
    "\n",
    "# add plot title\n",
    "ax.set_title('k-NN Classification Accuracy (scaled features)', fontsize=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3: Train, evaluate and plot the prediction accuracy of the Nearest Neighbor models without feature scaling.**\n",
    "\n",
    "> Similar to the exercises above, write a Python loop that trains and evaluates the prediction accuracy of all k-Nearest Neighbor parameterizations ranging from k=1,...,40 using the **original (non feature scaled) wine dataset**. Collect and print the prediction accuracy of each model respectively and compare the results (similar to exercise 1). Plot the prediction accuracy collected for each model above. The plot should display the distinct values of k at the x-axis and the corresponding model prediction accuracy on the y-axis (similar to exercise 2). What do you observe when comparing the results of the non re-scaled with the results obtained for the scaled features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***************************************************\n",
    "# INSERT YOUR SOLUTION/CODE HERE\n",
    "# ***************************************************\n",
    "\n",
    "# ***************************************************\n",
    "# Task 1: set the evaluation fraction to 30%\n",
    "# ***************************************************\n",
    "eval_fraction = ???\n",
    "\n",
    "# ***************************************************\n",
    "# Task 2: set a random seed\n",
    "# ***************************************************\n",
    "seed = ???\n",
    "\n",
    "# ***************************************************\n",
    "# Task 3: conduct the 70% training and 30% evaluation split using the 'train_test_split' function\n",
    "# ***************************************************\n",
    "X_train, X_eval, y_train, y_eval = train_test_split(???, ???, test_size=eval_fraction, random_state=seed)\n",
    "\n",
    "# ***************************************************\n",
    "# Task 4: define range k=1 through k=40 to be evaluated\n",
    "# ***************************************************\n",
    "k_range = ???\n",
    "\n",
    "# ***************************************************\n",
    "# Task 5: init evaluation accuracy score array\n",
    "# ***************************************************\n",
    "eval_accuracy_scores_non_scaled = ???\n",
    "\n",
    "# ***************************************************\n",
    "# we use a for-loop to iterate over the distinct k values\n",
    "# ***************************************************\n",
    "for k in k_range:\n",
    "    \n",
    "    # ***************************************************\n",
    "    # Task 6: init the k-NN classifier\n",
    "    # ***************************************************\n",
    "    knn = ???\n",
    "    \n",
    "    # ***************************************************\n",
    "    # Task 7: train the k-NN classifer on the training data\n",
    "    # ***************************************************\n",
    "    knn.fit(???)\n",
    "    \n",
    "    # ***************************************************\n",
    "    # Task 8: evaluate the k-NN classifier on the evaluation data\n",
    "    # ***************************************************\n",
    "    y_eval_pred = knn.predict(???)\n",
    "    \n",
    "    # ***************************************************\n",
    "    # Task 9: collect the classification accuracy of the current k on the evaluation data\n",
    "    # ***************************************************\n",
    "    eval_accuracy_scores_non_scaled.append(metrics.accuracy_score(???))\n",
    "\n",
    "# ***************************************************\n",
    "# prepare plot\n",
    "# ***************************************************\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# ***************************************************\n",
    "# Task 10: plot the classification accuracy of distinct k's\n",
    "# ***************************************************\n",
    "ax.plot(???, eval_accuracy_scores_non_scaled, color='green', marker='o')\n",
    "\n",
    "# ***************************************************\n",
    "# Note: the following code lines will plot the confusion matrix (no need to change them)\n",
    "# ***************************************************\n",
    "\n",
    "# add grid\n",
    "ax.grid(linestyle='dotted')\n",
    "\n",
    "# add axis range and legends\n",
    "ax.set_xlabel(\"[$k$-Nearest-Neighbors]\", fontsize=10)\n",
    "ax.set_ylabel(\"[% classification accuracy]\", fontsize=10)\n",
    "\n",
    "# add plot title\n",
    "ax.set_title('k-NN Classification Accuracy (non-scaled features)', fontsize=10);"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "eGwNwDKEt8lG",
    "D0Jnx-Ljt8lK",
    "CZaa0qAnt8lY",
    "mMSfpCPvt8l4",
    "n94u0rxat8su"
   ],
   "name": "lab_03b_exercise.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "222px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
