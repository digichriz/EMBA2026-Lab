{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" style=\"max-width: 1000px\" src=\"../assets/banner.png?raw=1\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B0cP5Z789_rr"
   },
   "source": [
    "<img align=\"right\" style=\"max-width: 200px; height: auto\" src=\"../assets/hsg_logo.png?raw=1\">\n",
    "\n",
    "##  Lab 05 - Convolutional Neural Networks (CNNs) - Assignments\n",
    "\n",
    "EMBA: Coding und KÃ¼nstliche Intelligenz, University of St. Gallen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rno8GqfC9_rz"
   },
   "source": [
    "In the last lab we learned how to enhance vanilla Artificial Neural Networks (ANNs) using `PyTorch` to classify even more complex images. Therefore, we used a special type of deep neural network referred to **Convolutional Neural Networks (CNNs)**. CNNs encompass the ability to take advantage of the hierarchical pattern in data and assemble more complex patterns using smaller and simpler patterns. In this lab, we aim to leverage that knowledge by applying it to a set of self-coding assignments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r93JK2DH9_r0"
   },
   "source": [
    "As always, please don't hesitate to ask all your questions either during the lab, post them in our CANVAS (StudyNet) forum (https://learning.unisg.ch), or send us an email (using the course email)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eW6dySzs9_r1"
   },
   "source": [
    "## 1. Assignment Objectives:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2uzc9Xr69_r1"
   },
   "source": [
    "Similar today's lab session, after today's self-coding assignments you should be able to:\n",
    "\n",
    "> 1. Understand the basic concepts, intuitions and major building blocks of **Convolutional Neural Networks (CNNs)**.\n",
    "> 2. Know how to **implement and to train a CNN** to learn a model of tiny image data.\n",
    "> 3. Understand how to apply such a learned model to **classify images** images based on their content into distinct categories.\n",
    "> 4. Know how to **interpret and visualize** the model's classification results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iPRKkkig9_r2"
   },
   "source": [
    "## 2. Setup of the Jupyter Notebook Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mZL4i6W9_r2"
   },
   "source": [
    "Similar to the previous labs, we need to import a couple of Python libraries that allow for data analysis and data visualization. We will mostly use the `PyTorch`, `Numpy`, `Sklearn`, `Matplotlib`, `Seaborn` and a few utility libraries throughout this lab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A9cwWtab9_r2"
   },
   "outputs": [],
   "source": [
    "# import standard python libraries\n",
    "import os, urllib, io\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FrB_51t89_r3"
   },
   "source": [
    "Import Python machine / deep learning libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZH6LhB_q9_r3"
   },
   "outputs": [],
   "source": [
    "# import the PyTorch deep learning library\n",
    "import torch, torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfgYux7K9_r3"
   },
   "source": [
    "Import the sklearn classification metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cFptYrnr9_r4"
   },
   "outputs": [],
   "source": [
    "# import sklearn classification evaluation library\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJJ5kfaf9_r4"
   },
   "source": [
    "Import Python plotting libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "usAgsocK9_r4"
   },
   "outputs": [],
   "source": [
    "# import matplotlib, seaborn, and PIL data visualization libary\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kZft6q1B9_r5"
   },
   "source": [
    "Enable notebook matplotlib inline plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BXnX3zt_9_r5"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZfE3I18r9_r5"
   },
   "source": [
    "Create notebook folder structure to store the data as well as the trained neural network models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nMFO6m7k9_r6"
   },
   "outputs": [],
   "source": [
    "# create the data sub-directory\n",
    "data_directory = './data_cifar10'\n",
    "if not os.path.exists(data_directory): os.makedirs(data_directory)\n",
    "\n",
    "# create the models sub-directory\n",
    "models_directory = './models_cifar10'\n",
    "if not os.path.exists(models_directory): os.makedirs(models_directory) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wcYgp4Gl9_r6"
   },
   "source": [
    "Set a random `seed` value to obtain reproducable results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vdbqEjHb9_r7"
   },
   "outputs": [],
   "source": [
    "# init deterministic seed\n",
    "seed_value = 1234\n",
    "\n",
    "np.random.seed(seed_value) # set numpy seed\n",
    "torch.manual_seed(seed_value) # set pytorch seed CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Convolutional Neural Networks (CNNs) Assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XH1CSkRV9_r8"
   },
   "source": [
    "### 3.1 CIFAR-10 Dataset Download and Data Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UWDn7IQE9_r8"
   },
   "source": [
    "The **CIFAR-10 database** (**C**anadian **I**nstitute **F**or **A**dvanced **R**esearch) is a collection of images that are commonly used to train machine learning and computer vision algorithms. The database is widely used to conduct computer vision research using machine learning and deep learning methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awuRyFMd9_r8"
   },
   "source": [
    "<img align=\"center\" style=\"max-width: 500px; height: 500px\" src=\"../lab_05/cifar10.png\">\n",
    "\n",
    "(Source: https://www.kaggle.com/c/cifar-10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjdI5VVN9_r8"
   },
   "source": [
    "Further details on the dataset can be obtained via: *Krizhevsky, A., 2009. \"Learning Multiple Layers of Features from Tiny Images\",  \n",
    "( https://www.cs.toronto.edu/~kriz/learning-features-2009-TR.pdf ).\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IaD13bmO9_r9"
   },
   "source": [
    "The CIFAR-10 database contains **60,000 color images** (50,000 training images and 10,000 validation images). The size of each image is 32 by 32 pixels. The collection of images encompasses 10 different classes that represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. Let's define the distinct classs for further analytics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1WlB2yXu9_r-"
   },
   "outputs": [],
   "source": [
    "cifar10_classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRslZNGV9_r-"
   },
   "source": [
    "Thereby the dataset contains 6,000 images for each of the ten classes. The CIFAR-10 is a straightforward dataset that can be used to teach a computer how to recognize objects in images.\n",
    "\n",
    "Let's download, transform and inspect the training images of the dataset. Therefore, we first will define the directory we aim to store the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B2Bmhc-c9_r-"
   },
   "outputs": [],
   "source": [
    "train_path = './data/train_cifar10'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b6AGBP_K9_r_"
   },
   "source": [
    "Now, let's download the training data accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G_-Zs4EU9_sA"
   },
   "outputs": [],
   "source": [
    "# define pytorch transformation into tensor format\n",
    "transf = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# download and transform training images\n",
    "cifar10_train_data = torchvision.datasets.CIFAR10(root=train_path, train=True, transform=transf, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g79sdHOw9_sA"
   },
   "source": [
    "Verify the volume of training images downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uiKFBLrI9_sA"
   },
   "outputs": [],
   "source": [
    "# get the length of the training data\n",
    "len(cifar10_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mWcoDhr_9_sC"
   },
   "source": [
    "Let's now decide on where we want to store the evaluation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hKFBcveC9_sC"
   },
   "outputs": [],
   "source": [
    "eval_path = './data/eval_cifar10'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nB5OpV4z9_sC"
   },
   "source": [
    "And download the evaluation data accordingly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L-OOVFFs9_sD"
   },
   "outputs": [],
   "source": [
    "# define pytorch transformation into tensor format\n",
    "transf = torchvision.transforms.Compose([torchvision.transforms.ToTensor(), torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# download and transform validation images\n",
    "cifar10_eval_data = torchvision.datasets.CIFAR10(root=eval_path, train=False, transform=transf, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WF4VrcHG9_sD"
   },
   "source": [
    "Let's also verfify the volume of validation images downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vhZRDL4X9_sD"
   },
   "outputs": [],
   "source": [
    "# get the length of the training data\n",
    "len(cifar10_eval_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B9Xivz3j9_sD"
   },
   "source": [
    "### 3.2 Convolutional Neural Network (CNN) Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nswYOXvk9_r0"
   },
   "source": [
    "<img align=\"center\" style=\"max-width: 900px\" src=\"../lab_05/classification.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tgqmaa129_sZ"
   },
   "source": [
    "We recommend you to try the following exercises as part of the self-coding session:\n",
    "\n",
    "**Exercise 1: Train the neural network architecture of the lab with increased learning rate.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Increase the learning rate of the network training to a value of **0.1** (instead of currently 0.001) and re-run the network training for 10 training epochs. Load and evaluate the model exhibiting the lowest training loss. What kind of behavior in terms of loss convergence and prediction accuracy can be observed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kx4C87LF9_sZ"
   },
   "outputs": [],
   "source": [
    "# ***************************************************\n",
    "# INSERT YOUR SOLUTION/CODE HERE\n",
    "# ***************************************************\n",
    "\n",
    "# ***************************************************\n",
    "# Task 1: define and init neural network architecture\n",
    "# ***************************************************\n",
    "\n",
    "# implement the CIFAR10Net network architecture\n",
    "class CIFAR10Net(nn.Module):\n",
    "    \n",
    "    # define the class constructor\n",
    "    def __init__(self):\n",
    "        \n",
    "        # ***************************************************\n",
    "        # insert the network architecture here\n",
    "        # ***************************************************\n",
    "        \n",
    "    # define network forward pass\n",
    "    def forward(self, images):\n",
    "        \n",
    "        # ***************************************************\n",
    "        # insert the network forwad pass here\n",
    "        # ***************************************************\n",
    "        \n",
    "        # return forward pass result\n",
    "        return x\n",
    "\n",
    "# init the neural network model\n",
    "model = ???\n",
    "\n",
    "# ***************************************************\n",
    "# Task 2: define loss, training hyperparameters and dataloader\n",
    "# ***************************************************\n",
    "\n",
    "# define the optimization criterion / loss function\n",
    "nll_loss = ???\n",
    "\n",
    "# define learning rate and optimization strategy\n",
    "learning_rate = ???\n",
    "optimizer = optim.SGD(params=model.parameters(), lr=learning_rate)\n",
    "\n",
    "# specify the training parameters\n",
    "num_epochs = ??? # number of training epochs\n",
    "mini_batch_size = ??? # size of the mini-batches\n",
    "\n",
    "# define training dataloader\n",
    "cifar10_train_dataloader = torch.utils.data.DataLoader(cifar10_train_data, batch_size=mini_batch_size, shuffle=True)\n",
    "\n",
    "# ***************************************************\n",
    "# Task 3: run model training\n",
    "# ***************************************************\n",
    "\n",
    "# init collection of training epoch losses\n",
    "train_epoch_losses = []\n",
    "\n",
    "# set the model in training mode\n",
    "model.train()\n",
    "\n",
    "# train the CIFAR10 model\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # init collection of mini-batch losses\n",
    "    train_mini_batch_losses = []\n",
    "    \n",
    "    # iterate over all-mini batches\n",
    "    for i, (images, labels) in enumerate(cifar10_train_dataloader):\n",
    "\n",
    "        # run forward pass through the network\n",
    "        output = ???\n",
    "        \n",
    "        # reset graph gradients\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # determine classification loss\n",
    "        loss = ???\n",
    "        \n",
    "        # run backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # update network paramaters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # collect mini-batch reconstruction loss\n",
    "        train_mini_batch_losses.append(loss.data.item())\n",
    "\n",
    "    # determine mean min-batch loss of epoch\n",
    "    train_epoch_loss = np.mean(train_mini_batch_losses)\n",
    "    \n",
    "    # print epoch loss\n",
    "    now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "    print('[LOG {}] epoch: {} train-loss: {}'.format(str(now), str(epoch), str(train_epoch_loss)))\n",
    "    \n",
    "    # save model to local directory\n",
    "    model_name = 'cifar10_model_epoch_{}.pth'.format(str(epoch))\n",
    "    torch.save(model.state_dict(), os.path.join(models_directory, model_name))\n",
    "    \n",
    "    # determine mean min-batch loss of epoch\n",
    "    train_epoch_losses.append(train_epoch_loss)\n",
    "\n",
    "# ***************************************************\n",
    "# Task 4: run model evaluation\n",
    "# ***************************************************\n",
    "\n",
    "# define eval dataloader\n",
    "cifar10_eval_dataloader = torch.utils.data.DataLoader(cifar10_eval_data, batch_size=10000, shuffle=False)\n",
    "\n",
    "# determine model predictions\n",
    "predictions = torch.argmax(model(???, dim=1)\n",
    "\n",
    "# determine accuracy scores\n",
    "accuracy = metrics.accuracy_score(???, ???)\n",
    "\n",
    "# print the classification accuracy percentage\n",
    "print('Final CIFAR10Net classification accuracy: {}%'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UNBnGfwU9_sa"
   },
   "source": [
    "**2. Evaluation of \"shallow\" vs. \"deep\" neural network architectures.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In addition to the architecture of the lab notebook, evaluate further (more **shallow** as well as more **deep**) neural network architectures by either **removing or adding convolutional layers** to the network. Train a model (using the architectures you selected) for at least **20 training epochs**. Analyze the prediction performance of the trained models in terms of training time and prediction accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h-zirkqH9_sa"
   },
   "outputs": [],
   "source": [
    "# ***************************************************\n",
    "# INSERT YOUR SOLUTION/CODE HERE\n",
    "# ***************************************************\n",
    "\n",
    "# ***************************************************\n",
    "# Task 1: define and init neural network architecture\n",
    "# ***************************************************\n",
    "\n",
    "# implement the CIFAR10Net network architecture\n",
    "class CIFAR10Net(nn.Module):\n",
    "    \n",
    "    # define the class constructor\n",
    "    def __init__(self):\n",
    "        \n",
    "        # call super class constructor\n",
    "        super(CIFAR10Net, self).__init__()\n",
    "        \n",
    "        # ***************************************************\n",
    "        # insert the network architecture here\n",
    "        # ***************************************************\n",
    "        \n",
    "    # define network forward pass\n",
    "    def forward(self, images):\n",
    "        \n",
    "        # ***************************************************\n",
    "        # insert the network forwad pass here\n",
    "        # ***************************************************\n",
    "        \n",
    "        # return forward pass result\n",
    "        return x\n",
    "    \n",
    "model = CIFAR10Net()\n",
    "\n",
    "# ***************************************************\n",
    "# Task 2: define loss, training hyperparameters and dataloader\n",
    "# ***************************************************\n",
    "\n",
    "# define the optimization criterion / loss function\n",
    "nll_loss = ???\n",
    "\n",
    "# define learning rate and optimization strategy\n",
    "learning_rate = ???\n",
    "optimizer = optim.SGD(params=model.parameters(), lr=learning_rate)\n",
    "\n",
    "# specify the training parameters\n",
    "num_epochs = ??? # number of training epochs\n",
    "mini_batch_size = ??? # size of the mini-batches\n",
    "\n",
    "# define training dataloader\n",
    "cifar10_train_dataloader = torch.utils.data.DataLoader(cifar10_train_data, batch_size=mini_batch_size, shuffle=True)\n",
    "\n",
    "# ***************************************************\n",
    "# Task 3: run model training\n",
    "# ***************************************************\n",
    "\n",
    "# init collection of training epoch losses\n",
    "train_epoch_losses = []\n",
    "\n",
    "# set the model in training mode\n",
    "model.train()\n",
    "\n",
    "# train the CIFAR10 model\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # init collection of mini-batch losses\n",
    "    train_mini_batch_losses = []\n",
    "    \n",
    "    # iterate over all-mini batches\n",
    "    for i, (images, labels) in enumerate(cifar10_train_dataloader):\n",
    "\n",
    "        # run forward pass through the network\n",
    "        output = ???\n",
    "        \n",
    "        # reset graph gradients\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # determine classification loss\n",
    "        loss = ???\n",
    "        \n",
    "        # run backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # update network paramaters\n",
    "        optimizer.step()\n",
    "        \n",
    "        # collect mini-batch reconstruction loss\n",
    "        train_mini_batch_losses.append(loss.data.item())\n",
    "\n",
    "    # determine mean min-batch loss of epoch\n",
    "    train_epoch_loss = np.mean(train_mini_batch_losses)\n",
    "    \n",
    "    # print epoch loss\n",
    "    now = datetime.utcnow().strftime(\"%Y%m%d-%H:%M:%S\")\n",
    "    print('[LOG {}] epoch: {} train-loss: {}'.format(str(now), str(epoch), str(train_epoch_loss)))\n",
    "    \n",
    "    # save model to local directory\n",
    "    model_name = 'cifar10_model_epoch_{}.pth'.format(str(epoch))\n",
    "    torch.save(model.state_dict(), os.path.join(models_directory, model_name))\n",
    "    \n",
    "    # determine mean min-batch loss of epoch\n",
    "    train_epoch_losses.append(train_epoch_loss)\n",
    "\n",
    "# ***************************************************\n",
    "# Task 4: run model evaluation\n",
    "# ***************************************************\n",
    "\n",
    "# define eval dataloader\n",
    "cifar10_eval_dataloader = torch.utils.data.DataLoader(cifar10_eval_data, batch_size=10000, shuffle=False)\n",
    "\n",
    "# determine model predictions\n",
    "predictions = torch.argmax(model(???, dim=1)\n",
    "\n",
    "# determine accuracy scores\n",
    "accuracy = metrics.accuracy_score(???, ???)\n",
    "\n",
    "# print the classification accuracy percentage\n",
    "print('Final CIFAR10Net classification accuracy: {}%'.format(accuracy * 100))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "eW6dySzs9_r1",
    "iPRKkkig9_r2",
    "XH1CSkRV9_r8",
    "B9Xivz3j9_sD",
    "rUeMEeHa9_sJ",
    "sWU9hWb_9_sO",
    "N8NnkvgF9_sR",
    "038JB6i49_sZ",
    "ST0oDfsq9_sk"
   ],
   "name": "ml_lab_05.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "254.39999389648438px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
